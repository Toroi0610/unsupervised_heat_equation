{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import yaml\n",
    "\n",
    "from unet_part import UNet, PCL\n",
    "\n",
    "from utils import convert_array_to_tensor, convert_tensor_to_array, getflow, get2orderderivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D - Heat equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diffusion equation\n",
    "\\begin{align*}\n",
    "\\frac{ \\partial u}{\\partial t}=\\kappa\\left(\\frac{\\partial^2u}{\\partial x^2} + \\frac{\\partial^2u}{\\partial y^2}\\right)\\ \\ \\ \n",
    "(0\\leq x \\leq x_h ,0\\leq y \\leq y_h , 0 \\leq t)\n",
    "\\end{align*}\n",
    "\n",
    "### Bounary condition\n",
    "\\begin{align*}\n",
    "u(x,0,t)=0 \\ \\ \\ (0\\leq x \\leq x_h) \\\\\n",
    "u(x,y_h,t)=T_0 \\ \\ \\ (0\\leq x \\leq x_h) \\\\\n",
    "u(0,y,t)=0 \\ \\ \\ (0\\leq y \\leq y_h) \\\\\n",
    "u(x_h,y,t)=0 \\ \\ \\ (0\\leq y \\leq y_h)\n",
    "\\end{align*}\n",
    "\n",
    "## discritisation\n",
    "\\begin{align*}\n",
    "\\frac{u(x, y, t+\\Delta t)-u(x, y, t)}{\\Delta t} = \\kappa \\left(\\frac{u(x+\\Delta x, y, t) - 2 u(x, y, t) + u(x-\\Delta x, y, t)}{\\Delta x^2} + \\frac{u(x, y + \\Delta y, t) - 2 u(x, y, t) + u(x, y - \\Delta y, t)}{\\Delta y^2}\\right)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Physics-Constrained Loss\n",
    "\\begin{align*}\n",
    "L_d = \\left|\\frac{ \\partial u}{\\partial t}-\\kappa\\left(\\frac{\\partial^2u}{\\partial x^2} + \\frac{\\partial^2u}{\\partial y^2}\\right)\\right|^{2}\\ \\ \\ \n",
    "(0\\leq x \\leq 1 ,0\\leq y \\leq 3 , 0 \\leq t)\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "L_b=\\left|u(x,0,t)\\right|^2+\\left|u(x,y_h,t)-T_0\\right|^2+\\left|u(0,y,t)\\right|^2+\\left|u(x_h,y,t)\\right|^2 \\ \\ \\ \n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "L_{all} = \\alpha_d  L_d + \\alpha_bL_b\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_params': {'alpha_d': 100, 'alpha_b': 100}, 'simulation_params': {'kappa': 0.01, 'x_h': 4, 'y_h': 8, 'dx': 0.01, 'dy': 0.01}}\n"
     ]
    }
   ],
   "source": [
    "with open(\"config.yaml\", \"r\") as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config[\"learning_params\"][\"alpha_d\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_h = config[\"simulation_params\"][\"x_h\"]\n",
    "y_h = config[\"simulation_params\"][\"y_h\"]\n",
    "dx = config[\"simulation_params\"][\"dx\"]\n",
    "dy = config[\"simulation_params\"][\"dy\"]\n",
    "\n",
    "init_temp = np.random.randint(0, 80, size=[int(x_h/dx), int(y_h/dy)]).astype(np.float32)\n",
    "\n",
    "# set bounary condition\n",
    "init_temp[:, -1] = config[\"simulation_params\"][\"T_0\"]\n",
    "\n",
    "temp_field = init_temp\n",
    "\n",
    "config[\"simulation_params\"][\"field_shape\"] = temp_field.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n",
      "Training loss (for one batch) at epoch 0: 1823955222528.0000\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at epoch 1: 3897684882704302080.0000\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss (for one batch) at epoch 2: 10786008203264.0000\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss (for one batch) at epoch 3: 575092490240.0000\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss (for one batch) at epoch 4: 111982362624.0000\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss (for one batch) at epoch 5: 713962815488.0000\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss (for one batch) at epoch 6: 1112307793920.0000\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss (for one batch) at epoch 7: 1284181721088.0000\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss (for one batch) at epoch 8: 1284820697088.0000\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss (for one batch) at epoch 9: 1126004424704.0000\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss (for one batch) at epoch 10: 845021970432.0000\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss (for one batch) at epoch 11: 527130984448.0000\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss (for one batch) at epoch 12: 267300044800.0000\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss (for one batch) at epoch 13: 103857291264.0000\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss (for one batch) at epoch 14: 11847894016.0000\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss (for one batch) at epoch 15: 13862396928.0000\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss (for one batch) at epoch 16: 79974006784.0000\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss (for one batch) at epoch 17: 112775675904.0000\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss (for one batch) at epoch 18: 92262236160.0000\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss (for one batch) at epoch 19: 42424889344.0000\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss (for one batch) at epoch 20: 7065851904.0000\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss (for one batch) at epoch 21: 121171124224.0000\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss (for one batch) at epoch 22: 2975507968.0000\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss (for one batch) at epoch 23: 15721696256.0000\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss (for one batch) at epoch 24: 15085581312.0000\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss (for one batch) at epoch 25: 7923700736.0000\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss (for one batch) at epoch 26: 1335196032.0000\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss (for one batch) at epoch 27: 783996928.0000\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss (for one batch) at epoch 28: 6119416832.0000\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss (for one batch) at epoch 29: 10624064512.0000\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss (for one batch) at epoch 30: 9363230720.0000\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss (for one batch) at epoch 31: 4821831680.0000\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss (for one batch) at epoch 32: 1098668800.0000\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss (for one batch) at epoch 33: 163411584.0000\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss (for one batch) at epoch 34: 1942465152.0000\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss (for one batch) at epoch 35: 4259930624.0000\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss (for one batch) at epoch 36: 4737916416.0000\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss (for one batch) at epoch 37: 3072051456.0000\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss (for one batch) at epoch 38: 886510080.0000\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss (for one batch) at epoch 39: 97400568.0000\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss (for one batch) at epoch 40: 1130184960.0000\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss (for one batch) at epoch 41: 2354298624.0000\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss (for one batch) at epoch 42: 2503785472.0000\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss (for one batch) at epoch 43: 1557876480.0000\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss (for one batch) at epoch 44: 422575136.0000\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss (for one batch) at epoch 45: 93379000.0000\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss (for one batch) at epoch 46: 624176320.0000\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss (for one batch) at epoch 47: 1268273152.0000\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss (for one batch) at epoch 48: 1334734464.0000\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss (for one batch) at epoch 49: 799962368.0000\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss (for one batch) at epoch 50: 214484704.0000\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss (for one batch) at epoch 51: 100503392.0000\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss (for one batch) at epoch 52: 444172800.0000\n",
      "\n",
      "Start of epoch 53\n"
     ]
    }
   ],
   "source": [
    "model.unsupervised_training(convert_array_to_tensor(init_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.call(convert_array_to_tensor(init_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
